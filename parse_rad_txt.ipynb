{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to parse text files to produce cleaned text of RAD decisions\n",
    "\n",
    "Sean Rehaag\n",
    "\n",
    "License: Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0). \n",
    "\n",
    "Dataset & Code to be cited as:\n",
    "\n",
    "Sean Rehaag, \"Refugee Appeal Division Bulk Decisions Dataset\" (2023), online: Refugee Law Laboratory <https://refugeelab.ca/bulk-data/rad/>.\n",
    "\n",
    "Notes:\n",
    "\n",
    "(1) Data Source: Immigration and Refugee Board. In the Fall of 2022, the IRB added the Refugee Law Laboratory to their email distribution list for legal publishers of RAD decisions. The RLL therefore receives new RAD cases as they are released for publication by the IRB. Also, in the fall of 2022 the Immigration and Refugee Board provided the RLL with a full backlog of approximately 116k published decisions from all divisions (RAD, RPD, ID, IAD). \n",
    "\n",
    "(2) Unofficial Data: The data are unofficial reproductions. For official versions, please contact the Immigration and Refugee Board. \n",
    "\n",
    "(3) Non-Affiliation / Endorsement: The data has been collected and reproduced without any affiliation or endorsement from the Immigration and Refugee Board.\n",
    "\n",
    "(4) Non-Commerical Use: As indicated in the license, data may be used for non-commercial use (with attribution) only. For commercial use, please contact the Immigration and Refugee Board. \n",
    "\n",
    "(5) Accuracy: Data was collected and processed programmatically for the purposes of academic research. While we make best efforts to ensure accuracy, data gathering of this kind inevitably involves errors. As such the data should be viewed as preliminary information aimed to prompt further research and discussion, rather than as definitive information.\n",
    "\n",
    "Acknowledgements: Thanks to Rafael Dolores for coding the parsing scripts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in c:\\users\\rafae\\anaconda3\\lib\\site-packages (1.0.9)\n",
      "Requirement already satisfied: six in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Requirement already satisfied: regex in c:\\users\\rafae\\anaconda3\\lib\\site-packages (2022.7.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect\n",
    "!pip install regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import regex as re \n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from langdetect import detect\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring Constant\n",
    "Here, we specify the directory containing our data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"DATA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Detection\n",
    "This function determines the language of a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Maker Extraction\n",
    "This function searches the given file for the decision maker using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_decision_maker(content):\n",
    "    patterns = [\n",
    "        r\"Panel\\s*([\\w\\s\\.-]+?)\\s*\\b(?!Panel|Tribunal)\\b\\s*Tribunal\",\n",
    "        r\"Tribunal\\s*([\\w\\s\\.-]+?)\\s*\\b(?!Panel|Tribunal)\\b\\s*Panel\"\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, content, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Date Extraction\n",
    "This function searches the given file for the document date using regular expressions, taking into account both French and English texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_document_date(content):\n",
    "    french_month_mapping = {\n",
    "        'janvier': 1, 'fevrier': 2, 'mars': 3, 'avril': 4,\n",
    "        'mai': 5, 'juin': 6, 'juillet': 7, 'aout': 8,\n",
    "        'septembre': 9, 'octobre': 10, 'novembre': 11, 'decembre': 12\n",
    "    }\n",
    "\n",
    "    # Capture both types of date formats, with a potential \"Le\" or \"1er\" for the French format.\n",
    "    pattern = r\"Date (?:of decision|de la décision)\\s+(?:Le )?((?:\\d{1,2}|1er) [\\w]+ \\d{4}|\\w+ \\d{1,2}(?:,)? \\d{4})\"\n",
    "    match = re.search(pattern, content, re.IGNORECASE)\n",
    "\n",
    "    if match:\n",
    "        parts = match.group(1).split(' ')\n",
    "        if parts[0].isdigit() or parts[0] == '1er':  # Day first, can be French or English\n",
    "            day, month, year = parts\n",
    "            day = 1 if day == '1er' else int(day)  # Handle '1er' case\n",
    "            month = month.lower().replace('é', 'e').replace('û', 'u').replace('ô', 'o')\n",
    "            if month in french_month_mapping:\n",
    "                return datetime(int(year), french_month_mapping[month], day).date().strftime('%Y-%m-%d')\n",
    "            else:\n",
    "                # Consider this as English and directly pass to datetime.strptime\n",
    "                return datetime.strptime(f\"{month} {day} {year}\", '%B %d %Y').date().strftime('%Y-%m-%d')\n",
    "        else:  # Month first, English format\n",
    "            month, day, year = parts[0], parts[1].replace(',', ''), parts[2]\n",
    "            return datetime.strptime(f\"{month} {day} {year}\", '%B %d %Y').date().strftime('%Y-%m-%d')\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting year with a comma\n",
    "Function that attaches commas to the year: 2000 => 2,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_year(year):\n",
    "    if year:\n",
    "        return '{:,}'.format(year)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Files\n",
    "This block of code reads each file in the DATA directory to extract the needed information, using the previously defined functions and form a Pandas dataframe which is provided in a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_records = []\n",
    "\n",
    "for file_name in os.listdir(DATA_DIR):\n",
    "    with open(os.path.join(DATA_DIR, file_name), 'r', errors='replace') as file:\n",
    "        content = file.read()\n",
    "        rad_number = None\n",
    "        for line in content.splitlines():\n",
    "            if \"RAD File\" in line:\n",
    "                rad_number_match = re.search(r\"([A-Z]{2}\\d+-\\d+)\", line)\n",
    "                if rad_number_match:\n",
    "                    rad_number = rad_number_match.group(1)\n",
    "                    break\n",
    "        lang = detect_language(content)\n",
    "        decision_maker_name = extract_decision_maker(content)\n",
    "        document_date = extract_document_date(content)\n",
    "        year = int(document_date.split('-')[0]) if document_date else None\n",
    "        formatted_year = format_year(year)\n",
    "\n",
    "        data_records.append({\n",
    "            'citation1': rad_number,\n",
    "            'citation2': '',\n",
    "            'dataset': 'RAD',\n",
    "            'name': '',\n",
    "            'source_url': file_name,\n",
    "            'scraped_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'document_date': document_date,\n",
    "            'year': formatted_year,\n",
    "            'unofficial_text': '',\n",
    "            'language': lang,\n",
    "            'other': json.dumps({'decision-maker_name': decision_maker_name}, ensure_ascii=False),\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placing output in CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_records)\n",
    "df['document_date'] = pd.to_datetime(df['document_date']).dt.strftime('%Y-%m-%d')\n",
    "df.to_csv('output.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
