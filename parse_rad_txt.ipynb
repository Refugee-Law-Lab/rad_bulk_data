{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to parse text files to produce cleaned text of RAD decisions\n",
    "\n",
    "Sean Rehaag\n",
    "\n",
    "License: Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0). \n",
    "\n",
    "Dataset & Code to be cited as:\n",
    "\n",
    "Sean Rehaag, \"Refugee Appeal Division Bulk Decisions Dataset\" (2023), online: Refugee Law Laboratory <https://refugeelab.ca/bulk-data/rad/>.\n",
    "\n",
    "Notes:\n",
    "\n",
    "(1) Data Source: Immigration and Refugee Board. In the Fall of 2022, the IRB added the Refugee Law Laboratory to their email distribution list for legal publishers of RAD decisions. The RLL therefore receives new RAD cases as they are released for publication by the IRB. Also, in the fall of 2022 the Immigration and Refugee Board provided the RLL with a full backlog of approximately 116k published decisions from all divisions (RAD, RPD, ID, IAD). \n",
    "\n",
    "(2) Unofficial Data: The data are unofficial reproductions. For official versions, please contact the Immigration and Refugee Board. \n",
    "\n",
    "(3) Non-Affiliation / Endorsement: The data has been collected and reproduced without any affiliation or endorsement from the Immigration and Refugee Board.\n",
    "\n",
    "(4) Non-Commerical Use: As indicated in the license, data may be used for non-commercial use (with attribution) only. For commercial use, please contact the Immigration and Refugee Board. \n",
    "\n",
    "(5) Accuracy: Data was collected and processed programmatically for the purposes of academic research. While we make best efforts to ensure accuracy, data gathering of this kind inevitably involves errors. As such the data should be viewed as preliminary information aimed to prompt further research and discussion, rather than as definitive information.\n",
    "\n",
    "Acknowledgements: Thanks to Rafael Dolores for coding the parsing scripts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langdetect\n",
    "#!pip install regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import regex as re \n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from langdetect import detect\n",
    "from difflib import get_close_matches\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring Constant\n",
    "Here, we specify the directories containing our data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRS = [\"../RAD Decisions TEXT\", \"../IRB Decisions - Initial Request - TEXT\"]\n",
    "\n",
    "# # For SR:\n",
    "# DATA_DIRS = [\"d:/RAD Decisions TEXT/\", \"d:/IRB Decisions - Initial Request - TEXT/\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Detection\n",
    "This function determines the language of a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Maker Extraction\n",
    "This function searches the given file for the decision maker using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_decision_maker(content):\n",
    "    patterns = [\n",
    "        # String in line immediately after 'Panel' and before 'Tribunal', allowing tabs and spaces\n",
    "        r\"^Panel\\s*([^\\n]+?)\\s*\\n\\s*Tribunal\\s*$\",  \n",
    "      \n",
    "        # String in line immediately after 'Tribunal' and before 'Panel', allowing tabs and spaces\n",
    "        r\"^Tribunal\\s*([^\\n]+?)\\s*\\n\\s*Panel\\s*$\",\n",
    "        # String in line immediately after 'Tribunal' and followed by another 'Tribunal', allowing tabs and spaces\n",
    "        r\"^Tribunal\\s*([^\\n]+?)\\s*\\n\\s*Tribunal\\s*$\"\n",
    "    ]\n",
    "\n",
    "    for pattern in patterns:\n",
    "        # Use re.MULTILINE to allow ^ and $ to match the start and end of each line\n",
    "        match = re.search(pattern, content, re.IGNORECASE | re.MULTILINE)\n",
    "        if match:\n",
    "            captured = match.group(1).strip()\n",
    "            # Check if captured group ends with 'Tribunal' or 'Panel' and exclude it\n",
    "            if not captured.endswith(\"Tribunal\") and not captured.endswith(\"Panel\"):\n",
    "                return captured\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Regular Expression Detector\n",
    "Functions to parse the date from text files while accounting for several different formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_date_patterns(content):\n",
    "    patterns = {\n",
    "        \"custom\": (r\"Date (?:of decision|de la décision)\\s*\\n\\s*([A-Za-z]+)\\s+(\\d{1,2})\\.\\s*(\\d{4})\", lambda m: [m.group(1), m.group(2), m.group(3)]),\n",
    "        \"primary\": (r\"Date (?:of decision|de la décision)\\s*(?:Le )?\\s*((?:(?:\\d{1,2}|1er)\\s+[\\w]+\\s*,?\\s*\\d{1,4})|\\w+\\s+\\d{1,2}(?:st|nd|rd|th)?\\s*,?\\s*\\d{1,4}|\\d{1,2}-\\d{1,2}-\\d{1,4})\", lambda m: m.group(1).replace(',', '').split()),\n",
    "        \"original_decision\": (r\"Date of decision\\s+([\\w\\s]+),\\s+(\\d{4})\\s+\\(original decision\\)\", lambda m: m.group(1).strip().split() + [m.group(2).strip()]),\n",
    "        \"tribunal\": (r\"Tribunal\\s*\\n\\s*([\\w\\s]+?)\\s*\\n\\s*Date of decision\", lambda m: m.group(1).replace(',', '').split()),\n",
    "        \"original\": (r\"Original\\s+([\\w]+\\s+\\d{1,2}(?:st|nd|rd|th)?,?\\s+\\d{4})\", lambda m: m.group(1).replace(',', '').split())\n",
    "    }\n",
    "\n",
    "    for key, (pattern, process) in patterns.items():\n",
    "        match = re.search(pattern, content, re.IGNORECASE)\n",
    "        if match:\n",
    "            return process(match)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Formatter\n",
    "Takes detected regular expression and converts into one common format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_to_english = {\n",
    "        'janvier': 'January', 'fevrier': 'February', 'mars': 'March', 'avril': 'April',\n",
    "        'mai': 'May', 'juin': 'June', 'juillet': 'July', 'aout': 'August',\n",
    "        'septembre': 'September', 'octobre': 'October', 'novembre': 'November', 'decembre': 'December'\n",
    "}\n",
    "\n",
    "def correct_month_name(misspelled_month, possibilities=['Janvier','January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'], cutoff=0.6):\n",
    "    correct_months = get_close_matches(misspelled_month, possibilities, n=1, cutoff=cutoff)\n",
    "    if correct_months:\n",
    "        corrected_month = correct_months[0]\n",
    "        # Check if the corrected month is in the French to English mapping\n",
    "        return french_to_english.get(corrected_month.lower(), corrected_month)\n",
    "    else:\n",
    "        return misspelled_month\n",
    "\n",
    "def correct_year_typo(year):\n",
    "    if len(year) == 3 and year.startswith(\"0\"):\n",
    "        return \"20\" + year[1:]\n",
    "    return year\n",
    "\n",
    "def correct_year_typo(year):\n",
    "    \"\"\"Corrects year format typos.\"\"\"\n",
    "    return \"20\" + year[1:] if len(year) == 3 and year.startswith(\"0\") else year\n",
    "\n",
    "def process_numeric_format(parts):\n",
    "    \"\"\"Processes numeric date format 'dd-mm-yyyy'.\"\"\"\n",
    "    day, month, year = parts[0].split('-')\n",
    "    year = correct_year_typo(year)\n",
    "    return datetime(int(year), int(month), int(day)).date().strftime('%Y-%m-%d')\n",
    "\n",
    "def process_day_first_format(parts, french_month_mapping):\n",
    "    \"\"\"Processes dates in 'day month year' format, French or English.\"\"\"\n",
    "    day = 1 if parts[0].lower() == '1er' else int(parts[0])\n",
    "\n",
    "    month = ''\n",
    "    # Check if month and year are concatenated\n",
    "    if len(parts) == 2 and not parts[1].isdigit():\n",
    "        month_year_str = parts[1]\n",
    "        for i in range(1, len(month_year_str)):\n",
    "            if month_year_str[i:].isdigit():\n",
    "                month_str, year_str = month_year_str[:i], month_year_str[i:]\n",
    "                year = correct_year_typo(year_str)\n",
    "                month = french_month_mapping.get(month_str.lower().replace('é', 'e').replace('û', 'u').replace('ô', 'o'), month_str.capitalize())\n",
    "                break\n",
    "    else:\n",
    "        month = parts[1].lower().replace('é', 'e').replace('û', 'u').replace('ô', 'o')\n",
    "        year = correct_year_typo(parts[2])\n",
    "\n",
    "    if month in french_month_mapping:\n",
    "        return datetime(int(year), french_month_mapping[month], day).date().strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        if isinstance(month, int):\n",
    "            return datetime(int(year), month, day).date().strftime('%Y-%m-%d')\n",
    "        \n",
    "        corrected_month = correct_month_name(month.capitalize())\n",
    "        try:\n",
    "            return datetime.strptime(f\"{corrected_month} {day} {year}\", '%B %d %Y').date().strftime('%Y-%m-%d')\n",
    "        except ValueError as e:\n",
    "            print(f\"Error parsing date: {e}\")\n",
    "            return None\n",
    "\n",
    "def process_month_first_format(parts):\n",
    "    \"\"\"Processes month first format with possible ordinal suffix.\"\"\"\n",
    "    day = 0\n",
    "    month = ''\n",
    "    year = ''\n",
    "    \n",
    "    if len(parts) == 2 and parts[1].isdigit() and len(parts[1]) > 2:\n",
    "        \n",
    "        if parts[1].isdigit() and len(parts[1]) > 4: \n",
    "            month = parts[0]\n",
    "            year_str = parts[1][-4:]\n",
    "            day_str = parts[1][:-4]\n",
    "            year = year_str\n",
    "            day = int(day_str)\n",
    "            \n",
    "        elif parts[1].isdigit()and len(parts[1]) > 3: #Year is the second entry\n",
    "            month_day_str = parts[0]\n",
    "            for i in range(1, len(month_day_str)):\n",
    "                if not month_day_str[i].isdigit():\n",
    "                    day_str, month_str = month_day_str[:i], month_day_str[i:]\n",
    "                    day = int(day_str)\n",
    "                    month = french_to_english.get(month_str.lower().replace('é', 'e').replace('û', 'u').replace('ô', 'o'), month_str)\n",
    "                    parts[0] = month\n",
    "                    break\n",
    "            year = parts[1]\n",
    "        else:\n",
    "            year_str = parts[1][-4:]\n",
    "            day_str = parts[1][:-4]\n",
    "            year = correct_year_typo(year_str)\n",
    "            day = int(day_str)\n",
    "\n",
    "    else:\n",
    "        day = re.sub(r\"[^\\d]\", \"\", parts[1])\n",
    "        day = int(day) if day.isdigit() else 1\n",
    "        year = correct_year_typo(parts[2])\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        corrected_month = correct_month_name(parts[0].capitalize())\n",
    "        return datetime.strptime(f\"{corrected_month} {day} {year}\", '%B %d %Y').date().strftime('%Y-%m-%d')\n",
    "    except ValueError as e:\n",
    "        print(f\"Error parsing date: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Date Extraction\n",
    "This function searches the given file for the document date using regular expressions, taking into account both French and English texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_date_parts(parts, french_month_mapping):\n",
    "    \"\"\"Determines the correct date processing method based on the format of the parts.\"\"\"\n",
    "    if '-' in parts[0]:\n",
    "        return process_numeric_format(parts)\n",
    "    elif parts[0].isdigit() or parts[0].lower() == '1er':\n",
    "        return process_day_first_format(parts, french_month_mapping)\n",
    "    else:\n",
    "        return process_month_first_format(parts)\n",
    "\n",
    "def extract_document_date(content):\n",
    "    french_month_mapping = {\n",
    "        'janvier': 1, 'fevrier': 2, 'mars': 3, 'avril': 4,\n",
    "        'mai': 5, 'juin': 6, 'juillet': 7, 'aout': 8,\n",
    "        'septembre': 9, 'octobre': 10, 'novembre': 11, 'decembre': 12\n",
    "    }\n",
    "    \n",
    "    parts = match_date_patterns(content)\n",
    "    if not parts:\n",
    "        return None\n",
    "    return process_date_parts(parts, french_month_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Processor Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rad_number(content):\n",
    "    \"\"\"Extracts the RAD number from the content, ignoring IAD files.\"\"\"\n",
    "    # Check for lines indicating the file should be ignored\n",
    "    ignore_lines = [\"IAD File\", \"IMMIGRATION APPEAL DIVISION\", \"RPD File\"]\n",
    "    for line in content.splitlines():\n",
    "        if any(ignore_line in line for ignore_line in ignore_lines):\n",
    "            return None\n",
    "\n",
    "        if \"RAD File\" in line:\n",
    "            rad_number_match = re.search(r\"([A-Z]{2}\\d+-\\d+)\", line)\n",
    "            if rad_number_match:\n",
    "                return rad_number_match.group(1)\n",
    "    return None\n",
    "\n",
    "def process_file(file_path):\n",
    "    \"\"\"Processes a single file and extracts data.\"\"\"\n",
    "    with open(file_path, 'r', errors='replace') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    rad_number = extract_rad_number(content)\n",
    "    if rad_number:\n",
    "        lang = detect_language(content)\n",
    "        decision_maker_name = extract_decision_maker(content)\n",
    "        document_date = extract_document_date(content)\n",
    "        year = int(document_date.split('-')[0]) if document_date else None\n",
    "\n",
    "        return {\n",
    "            'citation1': rad_number,\n",
    "            'citation2': '',\n",
    "            'dataset': 'RAD',\n",
    "            'name': '',\n",
    "            'source_url': os.path.basename(file_path),\n",
    "            #'scraped_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'scraped_timestamp': datetime.fromtimestamp(os.path.getmtime(file_path)).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'document_date': document_date,\n",
    "            'year': year,\n",
    "            'unofficial_text': content,\n",
    "            'language': lang,\n",
    "            'other': json.dumps({'decision-maker_name': decision_maker_name}, ensure_ascii=False),\n",
    "        }\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Files\n",
    "This block of code reads each file in the dataset directories to extract the needed information, using the previously defined functions and form a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3889/3889 [00:36<00:00, 105.41it/s]\n",
      "100%|██████████| 116688/116688 [03:32<00:00, 549.85it/s]  \n"
     ]
    }
   ],
   "source": [
    "# Main data processing loop\n",
    "data_records = []\n",
    "\n",
    "for data_dir in DATA_DIRS:\n",
    "    if os.path.exists(data_dir) and os.path.isdir(data_dir):\n",
    "        for file_name in tqdm(os.listdir(data_dir)):\n",
    "            #print(f\"Parsing file: {file_name}\")\n",
    "            if not file_name.startswith('~'):\n",
    "                file_path = os.path.join(data_dir, file_name)\n",
    "                record = process_file(file_path)\n",
    "                if record:\n",
    "                    data_records.append(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to DF and data cleaning\n",
    "Converts into dataframe and cleans data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citation1</th>\n",
       "      <th>citation2</th>\n",
       "      <th>dataset</th>\n",
       "      <th>name</th>\n",
       "      <th>source_url</th>\n",
       "      <th>scraped_timestamp</th>\n",
       "      <th>document_date</th>\n",
       "      <th>year</th>\n",
       "      <th>unofficial_text</th>\n",
       "      <th>language</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MB7-00112</td>\n",
       "      <td></td>\n",
       "      <td>RAD</td>\n",
       "      <td></td>\n",
       "      <td>MB7-00112a.txt</td>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>2020-09-15</td>\n",
       "      <td>2020</td>\n",
       "      <td>\\nRAD File / Dossier de la SAR : MB7-00112\\n\\n...</td>\n",
       "      <td>en</td>\n",
       "      <td>{\"decision-maker_name\": \"Me Richard Sheitoyan\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MB7-00112</td>\n",
       "      <td></td>\n",
       "      <td>RAD</td>\n",
       "      <td></td>\n",
       "      <td>MB7-00112tf.txt</td>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>2020-09-15</td>\n",
       "      <td>2020</td>\n",
       "      <td>\\nDossier de la SAR / RAD File: MB7-00112\\n\\nH...</td>\n",
       "      <td>fr</td>\n",
       "      <td>{\"decision-maker_name\": \"Me Richard Sheitoyan\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MB7-03926</td>\n",
       "      <td></td>\n",
       "      <td>RAD</td>\n",
       "      <td></td>\n",
       "      <td>MB7-03926f.txt</td>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>2020</td>\n",
       "      <td>\\nDossier de la SAR / RAD File : MB7-03926\\nMB...</td>\n",
       "      <td>fr</td>\n",
       "      <td>{\"decision-maker_name\": \"Normand Leduc\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MB7-03926</td>\n",
       "      <td></td>\n",
       "      <td>RAD</td>\n",
       "      <td></td>\n",
       "      <td>MB7-03926ta.txt</td>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>2020</td>\n",
       "      <td>\\nRAD File No. / No de dossier de la SAR : MB7...</td>\n",
       "      <td>en</td>\n",
       "      <td>{\"decision-maker_name\": \"Normand Leduc\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MB7-24221</td>\n",
       "      <td></td>\n",
       "      <td>RAD</td>\n",
       "      <td></td>\n",
       "      <td>MB7-24221 f.txt</td>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>2021</td>\n",
       "      <td>\\nDossier de la SAR / RAD File : MB7-24221\\n\\n...</td>\n",
       "      <td>fr</td>\n",
       "      <td>{\"decision-maker_name\": \"Normand Leduc\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26843</th>\n",
       "      <td>TC0-10861</td>\n",
       "      <td></td>\n",
       "      <td>RAD</td>\n",
       "      <td></td>\n",
       "      <td>3599965.txt</td>\n",
       "      <td>2023-11-13</td>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>2021</td>\n",
       "      <td>\\nDossier de la SAR / RAD File: TC0-10861\\n\\nH...</td>\n",
       "      <td>fr</td>\n",
       "      <td>{\"decision-maker_name\": \"J. Pollock\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26844</th>\n",
       "      <td>TB9-20994</td>\n",
       "      <td></td>\n",
       "      <td>RAD</td>\n",
       "      <td></td>\n",
       "      <td>3601134.txt</td>\n",
       "      <td>2023-11-13</td>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>2020</td>\n",
       "      <td>\\nRAD File / Dossier de la SAR : TB9-20994\\n\\n...</td>\n",
       "      <td>en</td>\n",
       "      <td>{\"decision-maker_name\": \"T. Card\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26845</th>\n",
       "      <td>TB9-20994</td>\n",
       "      <td></td>\n",
       "      <td>RAD</td>\n",
       "      <td></td>\n",
       "      <td>3601135.txt</td>\n",
       "      <td>2023-11-13</td>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>2020</td>\n",
       "      <td>\\nDossier de la SAR / RAD File: TB9-20994\\n\\nH...</td>\n",
       "      <td>fr</td>\n",
       "      <td>{\"decision-maker_name\": \"T. Card\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26846</th>\n",
       "      <td>TC0-09230</td>\n",
       "      <td></td>\n",
       "      <td>RAD</td>\n",
       "      <td></td>\n",
       "      <td>3601140.txt</td>\n",
       "      <td>2023-11-13</td>\n",
       "      <td>2021-02-22</td>\n",
       "      <td>2021</td>\n",
       "      <td>\\nRAD File / Dossier de la SAR : TC0-09230\\nTC...</td>\n",
       "      <td>en</td>\n",
       "      <td>{\"decision-maker_name\": \"E. Rose\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26847</th>\n",
       "      <td>TC0-09230</td>\n",
       "      <td></td>\n",
       "      <td>RAD</td>\n",
       "      <td></td>\n",
       "      <td>3601141.txt</td>\n",
       "      <td>2023-11-13</td>\n",
       "      <td>2021-02-22</td>\n",
       "      <td>2021</td>\n",
       "      <td>Dossier de la SAR / RAD File: TC0-09230\\nTC0-0...</td>\n",
       "      <td>fr</td>\n",
       "      <td>{\"decision-maker_name\": \"E. Rose\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26359 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       citation1 citation2 dataset name       source_url scraped_timestamp   \n",
       "2      MB7-00112               RAD        MB7-00112a.txt        2023-11-12  \\\n",
       "3      MB7-00112               RAD       MB7-00112tf.txt        2023-11-12   \n",
       "4      MB7-03926               RAD        MB7-03926f.txt        2023-11-12   \n",
       "5      MB7-03926               RAD       MB7-03926ta.txt        2023-11-12   \n",
       "6      MB7-24221               RAD       MB7-24221 f.txt        2023-11-12   \n",
       "...          ...       ...     ...  ...              ...               ...   \n",
       "26843  TC0-10861               RAD           3599965.txt        2023-11-13   \n",
       "26844  TB9-20994               RAD           3601134.txt        2023-11-13   \n",
       "26845  TB9-20994               RAD           3601135.txt        2023-11-13   \n",
       "26846  TC0-09230               RAD           3601140.txt        2023-11-13   \n",
       "26847  TC0-09230               RAD           3601141.txt        2023-11-13   \n",
       "\n",
       "      document_date  year                                    unofficial_text   \n",
       "2        2020-09-15  2020  \\nRAD File / Dossier de la SAR : MB7-00112\\n\\n...  \\\n",
       "3        2020-09-15  2020  \\nDossier de la SAR / RAD File: MB7-00112\\n\\nH...   \n",
       "4        2020-10-26  2020  \\nDossier de la SAR / RAD File : MB7-03926\\nMB...   \n",
       "5        2020-10-26  2020  \\nRAD File No. / No de dossier de la SAR : MB7...   \n",
       "6        2021-04-01  2021  \\nDossier de la SAR / RAD File : MB7-24221\\n\\n...   \n",
       "...             ...   ...                                                ...   \n",
       "26843    2021-05-25  2021  \\nDossier de la SAR / RAD File: TC0-10861\\n\\nH...   \n",
       "26844    2020-07-30  2020  \\nRAD File / Dossier de la SAR : TB9-20994\\n\\n...   \n",
       "26845    2020-07-30  2020  \\nDossier de la SAR / RAD File: TB9-20994\\n\\nH...   \n",
       "26846    2021-02-22  2021  \\nRAD File / Dossier de la SAR : TC0-09230\\nTC...   \n",
       "26847    2021-02-22  2021  Dossier de la SAR / RAD File: TC0-09230\\nTC0-0...   \n",
       "\n",
       "      language                                            other  \n",
       "2           en  {\"decision-maker_name\": \"Me Richard Sheitoyan\"}  \n",
       "3           fr  {\"decision-maker_name\": \"Me Richard Sheitoyan\"}  \n",
       "4           fr         {\"decision-maker_name\": \"Normand Leduc\"}  \n",
       "5           en         {\"decision-maker_name\": \"Normand Leduc\"}  \n",
       "6           fr         {\"decision-maker_name\": \"Normand Leduc\"}  \n",
       "...        ...                                              ...  \n",
       "26843       fr            {\"decision-maker_name\": \"J. Pollock\"}  \n",
       "26844       en               {\"decision-maker_name\": \"T. Card\"}  \n",
       "26845       fr               {\"decision-maker_name\": \"T. Card\"}  \n",
       "26846       en               {\"decision-maker_name\": \"E. Rose\"}  \n",
       "26847       fr               {\"decision-maker_name\": \"E. Rose\"}  \n",
       "\n",
       "[26359 rows x 11 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to dataframe\n",
    "df = pd.DataFrame(data_records)\n",
    "\n",
    "# fix dates format\n",
    "df['document_date'] = pd.to_datetime(df['document_date']).dt.strftime('%Y-%m-%d')\n",
    "df['scraped_timestamp'] = pd.to_datetime(df['scraped_timestamp']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# drop where year is nan\n",
    "df = df.dropna(subset=['year'])\n",
    "\n",
    "# convert year to int\n",
    "df['year'] = df['year'].astype(int)\n",
    "\n",
    "# Remove rows where unofficial text is duplicated, keeping the last one\n",
    "df = df.drop_duplicates(subset=['unofficial_text'], keep='last')\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exports to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00,  7.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# get start and end year\n",
    "start_year = df['year'].min()\n",
    "end_year = df['year'].max()\n",
    "\n",
    "# set output dir\n",
    "output_dir = 'DATA/YEARLY'\n",
    "\n",
    "# export cleaned df to yearly / language json files\n",
    "for year in tqdm(range(start_year, end_year+1)):\n",
    "    for language in ['en', 'fr']:\n",
    "        out_path_yearly_lang = output_dir + \"/\"+ f'{year}_{language}.json'\n",
    "        df[(df.year == year) & (df.language == language)].to_json(out_path_yearly_lang, orient='records', indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
